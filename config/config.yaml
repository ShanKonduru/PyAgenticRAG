llm:
  provider: "ollama"
  model: "llama3"
  temperature: 0.7
  max_tokens: 2000

vector_db:
  provider: "chroma"
  collection_name: "pyagentic_rag"
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  chunk_size: 1000
  chunk_overlap: 200

data_sources:
  enabled_sources:
    - "local_files"
  local_data_path: "./data"

agents:
  max_iterations: 5
  timeout_seconds: 60
  enable_memory: true
  memory_window: 10

api:
  host: "localhost"
  port: 8000
  debug: false
  cors_origins:
    - "*"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_path: "./logs/pyagentic_rag.log"
  max_file_size: "10MB"
  backup_count: 5